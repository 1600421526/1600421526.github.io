<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>LOOM-Scope - LOng-cOntext Model evaluation framework</title>
    <meta name="description" content="Providing a convient and comprehensive framework for long-context model evaluation.">
    <link rel="stylesheet" href="styles.css">
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.5.1/css/all.min.css">
    <style>
        
    </style>
</head>
<body>
    <main>
        <section class="hero">
            <h1>LOOM-Scope</h1>
            <h2>Providing a convient and comprehensive framework for long-context model evaluation.</h2>            
            <div class="nav-buttons">
                <a href="" class="button">
                    <i class="fas fa-file-alt"></i>
                    Paper
                </a>
                <a href="https://gitlab.com/ZetangForward1/LOOM-Scape" class="button">
                    <i class="fab fa-github"></i>
                    Code
                </a>
                <a href="" class="button">
                    <i class="fas fa-video"></i>
                    Video
                </a>
            </div>
        </section>

        <section class="introduction">
            <h2><i class="fas fa-info-circle"></i> Introduction</h2>
            <div class="overview-image" style="display: flex; flex-direction: column; align-items: center; text-align: center;">
                <div id="sunburst-chart" style="max-width: 100%; width: 800px; height: 600px;">
                </div>
                <p class="image-caption">
                    Sunburst Chart of LOOM - Scope with all of our benchmarks (classified)
                </p>
            </div>
        </section>
        <script src="https://cdn.plot.ly/plotly-latest.min.js"></script>
        
        <script>
            // ÂÆö‰πâÊ†áÁ≠æÔºàlabelsÔºâÂíåÁà∂ËäÇÁÇπÔºàparentsÔºâ
            const labels = ["Synthetic Tasks", "Real-World Tasks", "S-Doc QA", "M-Doc QA", "Choose", "Long QA", "Summ", "Writing", " Synthetic Recall ", "Synthetic Recall", "Code & Math", "Code & Math ", "Cite", "ICL", " RULER", " LongIns", "LEval", "LVEval", " LongBench-V2 ", " RULER ", "Babilong ", " LongIns ", " NThread ", " Babilong", "LongIns  ", "L-Cite-Eval ", "LEval ", "LongBench ", "LooGLE ", "InfiniteBench ", " LEval", "LongWriter", " LEval ", "LVEval ", " LongBench", " LooGLE", " LIBRA", " L-Cite-Eval", "LongBench-V2", " InfiniteBench", "LIBRA ", " LongBench ", "LongBench-V2 ", "LEval  ", " LVEval ", " LongBench-V2", "RULER", "Babilong", " InfiniteBench ", "LongIns", "NThread", "L-Cite-Eval  ", "  LEval", "LVEval  ", "LongBench  ", "RULER ", "InfiniteBench  ", "LongIns ", "Counting-Stars", "   NIAH   ", "NThread ", " LIBRA ", "  LEval  ", "  LVEval  ", "  InfiniteBench  "]
            const parents = ["", "", "Synthetic Tasks", "Synthetic Tasks", "Synthetic Tasks", "Real-World Tasks", "Real-World Tasks", "Real-World Tasks", "Synthetic Tasks", "Real-World Tasks", "Synthetic Tasks", "Real-World Tasks", "Real-World Tasks", "Real-World Tasks", "S-Doc QA", "S-Doc QA", "M-Doc QA", "M-Doc QA", "M-Doc QA", "M-Doc QA", "M-Doc QA", "M-Doc QA", "M-Doc QA", "Choose", "Choose", "Summ", "Summ", "Summ", "Summ", "Summ", "Writing", "Writing", "Synthetic Recall", "Synthetic Recall", "Synthetic Recall", "Synthetic Recall", "Synthetic Recall", "Cite", "Code & Math ", "Code & Math ", "Code & Math ", "ICL", "ICL", "Long QA", "Long QA", "Long QA", "Long QA", "Long QA", "Long QA", "Long QA", "Long QA", " Synthetic Recall ", " Synthetic Recall ", " Synthetic Recall ", " Synthetic Recall ", " Synthetic Recall ", " Synthetic Recall ", " Synthetic Recall ", " Synthetic Recall ", " Synthetic Recall ", " Synthetic Recall ", " Synthetic Recall ", "Code & Math", "Code & Math", "Code & Math"];
            const values = [650, 650, 52, 182, 52, 200, 125, 50, 286, 125, 78, 75, 25, 50, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26];
            const x = 14 + 11 + 5 + 2 + 5 + 1 + 3 + 2 + 8 + 11 + 3;
            const labels_trimmed = labels.slice(0, x);
            const parents_trimmed = parents.slice(0, x);
            const values_trimmed = values.slice(0, x);
        
            // ÂÆö‰πâÈ¢úËâ≤
            const colors = [];
            const main_colors = ["#1f77b4", "#ff7f0e"]; // ‰∏ªÁ±ªÂà´È¢úËâ≤
            const secondary_colors = ["#aec7e8", "#ffbb78"]; // ‰∫åÁ∫ßÁ±ªÂà´È¢úËâ≤
            const tertiary_colors = ["#c6dbef", "#fdd0a2"]; // ‰∏âÁ∫ßÁ±ªÂà´È¢úËâ≤
        
            for (let i = 0; i < labels_trimmed.length; i++) {
                const label = labels_trimmed[i];
                const parent = parents_trimmed[i];
                if (parent === "") {
                    colors.push(main_colors[labels_trimmed.indexOf(label)]);
                } else if (parent === "Synthetic Tasks" || parent === "Real-World Tasks") {
                    const index = labels_trimmed.indexOf(parent) % 2;
                    colors.push(secondary_colors[index]);
                } else {
                    const index = labels_trimmed.indexOf(parent) % 2;
                    if (parent === "Summ" || parent === "Cite") {
                        colors.push(tertiary_colors[1]);
                    } else if (parent === "M-Doc QA") {
                        colors.push(tertiary_colors[0]);
                    } else {
                        colors.push(tertiary_colors[index]);
                    }
                }
            }
        
            const fig = {
                data: [{
                    type: 'sunburst',
                    labels: labels_trimmed,
                    parents: parents_trimmed,
                    values: values_trimmed,
                    branchvalues: "total",
                    maxdepth: 3,
                    marker: {
                        colors: colors,
                        line: {
                            color: 'white',
                            width: 0.5
                        }
                    },
                    hovertemplate: '<b>%{label}</b><br>Value: %{value}<extra></extra>'
                }],
                layout: {
                    margin: { t: 20, l: 20, r: 20, b: 20 },
                    font: {
                        size: 12,
                        color: "black"
                    },
                    autosize: false,
                    width: 800,
                    height: 600,
                    paper_bgcolor: "transparent", // ÁîªÂ∏ÉËÉåÊôØÈÄèÊòé
                    plot_bgcolor: "transparent"  // ÁªòÂõæÂå∫ÂüüËÉåÊôØÈÄèÊòé
                }
            };
        
            // Ê∏≤ÊüìÂõæË°®Âà∞ÊåáÂÆöÁöÑ div ÂÖÉÁ¥†‰∏≠
            Plotly.newPlot('sunburst-chart', fig);
        </script>
            <p> 
                üî• LOOM-Scope offers a comprehensive suite of tools, featuring 15 standard long-context benchmarks covering faithfulness, retrieval, reasoning, generation, and more. With hundreds of subtasks and support for diverse model architectures including Transformers, Mamba, and RWKV it enables researchers to rigorously assess model capabilities under real-world long-context demands. A standout feature is its single-line command workflow, automating dataset/model detection, download, and evaluation for seamless usability.<br>
                <br>
                üöÄ Efficiency is at the core of LOOM-Scope: it integrates 12 computational acceleration methods like CakeKV and FlexPrefill, leveraging vLLM for fast, memory-efficient inference. We have evaluated a range of GPU hardware, from the 3090 with 24GB VRAM to the H20 with 96GB VRAM, and publicly documented their computational costs while ensuring reproducible results across platforms. Whether evaluating base models or adapters (via HuggingFace PEFT), LOOM-Scope ensures consistency and scalability.<br>
            </p>
            
                
        </section>
        <th class="sortable" data-sort="score">Avg Score</th>




        <section class="evaluation">
            const scores= {
            "Qwen3-30B-A3B":[37.96,40.61,11.61,78.32,43.24,60.31,48.96,41.30,22.82,28.42,100.00,24.12,14.14,83.24,56.09],
            "Qwen3-14B":[35.64,43.84,11.79,74.94,45.47,59.15,56.41,31.95,21.26,29.85,100.00,27.35,10.24,85.75,55.87],
            "Meta-Llama-3.1-8B-Instruct":[5.79,39.70,11.81,86.79,37.94,57.42,37.68,25.40,25.66,30.40,91.00,20.06,33.64,45.96,51.24],
            "Qwen3-8B":[33.18,41.15,11.67,67.68,38.62,55.28,52.32,32.61,15.15,27.25,64.00,21.92,8.06,81.99,51.78],
            "Qwen3-4B":[24.55,39.03,11.69,70.29,39.32,55.01,42.06,33.66,18.24,32.52,62.00,17.95,13.05,74.25,46.92]
            };
            const sequence = ["L_CiteEval",	"LEval","LooGLE", "RULERÔºà0-128kÔºâ, "longbench","babilongÔºà0-128kÔºâ", "Counting-Stars", "LongIns" ,"LVEval", "longbench_v2", "NIAH","NThread","InfiniteBench" ,"LongWriter","LIBRA" ]
            const ability = {
            "Faithfulness": ["L_CiteEval"], 
            "General": ["LEval", "LooGLE", "RULERÔºà0-128kÔºâ", "longbench"],
            "Reasoning": ["Counting-Stars", "LongIns", "LVEval", "longbench_v2", "NIAH"], 
            "Retrieval": ["NThread", "InfiniteBench", "LongWriter"], 
            "Generation": ["LongWriter"], 
            "Specialization": ["LIBRA"] 
            };


    
            <h2><i class="fas fa-chart-bar"></i> Model leaderboard</h2>
            <p> 
                The model leaderboard showcases performance rankings across LOOM-Scope's multidimensional benchmarks, evaluating models on key capabilities including Faithfulness, General tasks, Reasoning, Retrieval, Generation, and Specialization.
            </p> 
            <div class="table-container">
                <table>
                    <thead>
                        <tr>
                            <th rowspan="3" class="basic-header rank-col">Rank</th>
                            <th rowspan="2" class="basic-header model-col">Model</th>
                            <th rowspan="2" class="basic-header score-col">Avg Score</th>
                            <th colspan="1" class="algorithm-group">Faithfulness</th>
                            <th colspan="4" class="algorithm-group">General</th>
                            <th colspan="5" class="algorithm-group">Reasoning</th>
                            <th colspan="3" class="algorithm-group">Retrieval</th>
                            <th colspan="1" class="algorithm-group">Generation</th>
                            <th colspan="1" class="algorithm-group">Specialization</th>
                        </tr>
                        <tr>
                            <th class="algorithm-col">L_CiteEval</th>
                            <th class="algorithm-col">LEval</th>
                            <th class="algorithm-col">LooGLE</th>
                            <th class="algorithm-col">RULERÔºà0-128kÔºâ</th>
                            <th class="algorithm-col">longbench</th>
                            <th class="algorithm-col">babilongÔºà0-128kÔºâ</th>
                            <th class="algorithm-col">Counting-Stars</th>
                            <th class="algorithm-col">LongIns</th>
                            <th class="algorithm-col">LVEval</th>
                            <th class="algorithm-col">longbench_v2</th>
                            <th class="algorithm-col">NIAH</th>
                            <th class="algorithm-col">NThread</th>
                            <th class="algorithm-col">InfiniteBench</th>
                            <th class="algorithm-col">LongWriter</th>
                            <th class="algorithm-col">LIBRA</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td>1</td>
                            <td><span class="model-label Qwen">Qwen3-30B-A3B</span></td>
                            <td class="best-score">46.08</td> 
                            <td>37.96</td>
                            <td>40.61</td>
                            <td>11.61</td>
                            <td>78.32</td>
                            <td>43.24</td>
                            <td>60.31</td>
                            <td>48.96</td>
                            <td>41.30</td>
                            <td>22.82</td>
                            <td>28.42</td>
                            <td>100.00</td>
                            <td>24.12</td>
                            <td>14.14</td>
                            <td>83.24</td>
                            <td>56.09</td>
                        </tr>    
                        <tr>
                            <td>2</td>
                            <td><span class="model-label Qwen">Qwen3-14B</span></td>
                            <td class="best-score">45.97</td>
                            <td>35.64</td>
                            <td>43.84</td>
                            <td>11.79</td>
                            <td>74.94</td>
                            <td>45.47</td>
                            <td>59.15</td>
                            <td>56.41</td>
                            <td>31.95</td>
                            <td>21.26</td>
                            <td>29.85</td>
                            <td>100.00</td>
                            <td>27.35</td>
                            <td>10.24</td>
                            <td>85.75</td>
                            <td>55.87</td>
                        </tr>
                        <tr>
                            <td>3</td>
                            <td><span class="model-label Llama">Meta-Llama-3.1-8B-Instruct</span></td>
                            <td class="best-score">41.37</td>
                            <td>25.79</td>
                            <td>39.70</td>
                            <td>11.81</td>
                            <td>86.79</td>
                            <td>37.94</td>
                            <td>57.42</td>
                            <td>37.68</td>
                            <td>25.40</td>
                            <td>25.66</td>
                            <td>30.40</td>
                            <td>91.00</td>
                            <td>20.06</td>
                            <td>33.64</td>
                            <td>45.96</td>
                            <td>51.24</td>
                        </tr>
                        <tr>
                            <td>4</td>
                            <td><span class="model-label Qwen">Qwen3-8B</span></td>
                            <td class="best-score">40.18</td>
                            <td>33.18</td>
                            <td>41.15</td>
                            <td>11.67</td>
                            <td>67.68</td>
                            <td>38.62</td>
                            <td>55.28</td>
                            <td>52.32</td>
                            <td>32.61</td>
                            <td>15.15</td>
                            <td>27.25</td>
                            <td>64.00</td>
                            <td>21.92</td>
                            <td>8.06</td>
                            <td>81.99</td>
                            <td>51.78</td>
                        </tr>
                        <tr>
                            <td>5</td>
                            <td><span class="model-label Qwen">Qwen3-4B</span></td>
                            <td class="best-score">38.70</td>
                            <td>24.55</td>
                            <td>39.03</td>
                            <td>11.69</td>
                            <td>70.29</td>
                            <td>39.32</td>
                            <td>55.01</td>
                            <td>42.06</td>
                            <td>33.66</td>
                            <td>18.24</td>
                            <td>32.52</td>
                            <td>62.00</td>
                            <td>17.95</td>
                            <td>13.05</td>
                            <td>74.25</td>
                            <td>46.92</td>
                        </tr>    
                    </tbody>
                </table>
            </div>
        </section>
 
        
        <section class="evaluation">
            <h2><i class="fa-solid fa-flask"></i> Benchmark Validation Platform</h2>
            <p>
                The Benchmark Validation Platform provides a side-by-side comparison of scores from our framework‚Äôs evaluations and official scores reported in benchmark papers, demonstrating research findings‚Äô reproducibility.
            </p>
            <div class="table-container">
                <table>
                    <thead>
                        <tr>
                            <th rowspan="3" class="basic-header rank-col">Ability</th>
                            <th rowspan="3" class="basic-header rank-col">Benchmark</th>
                            <th rowspan="3" class="basic-header rank-col">Model</th>
                            <th rowspan="3" class="basic-header model-col">Scores (Evaluated)</th>
                            <th rowspan="3" class="basic-header score-col">Official Scores (Reported in Paper)</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td rowspan="5">Reasoning</td>
                            <td>babilong</td>
                            <td><span class="model-label Retrieval">Llama-3.1-8B-Instruct</span></td>
                            <td>57.0</td>
                            <td>59.0</td>
                        </tr>
                        <tr>
                            <td>Counting_Stars</td>
                            <td><span class="model-label Retrieval">Llama-3.1-8B-Instruct</span></td>
                            <td>38.2</td>
                            <td>43.5</td>
                        </tr>
                        <tr>
                            <td>LongBench_v2</td>
                            <td><span class="model-label Retrieval">Llama-3.1-8B-Instruct</span></td>
                            <td>30.4</td>
                            <td>30.0</td>
                        </tr>
                        <tr>
                            <td>LongIns</td>
                            <td><span class="model-label Specialization">ChatGLM2-6B</span></td>
                            <td>11.5</td>
                            <td>12.0</td>
                        </tr>
                        <tr>
                            <td>LVEval</td>
                            <td><span class="model-label Retrieval">Llama2-7B-32k-Instruct</span></td>
                            <td>7.3</td>
                            <td>7.4</td>
                        </tr>
                        <tr>
                            <td rowspan="4">General</td>
                            <td>LEval</td>
                            <td><span class="model-label Retrieval">Llama-3.1-8B-Instruct</span></td>
                            <td>60.5</td>
                            <td>58.7</td>
                        </tr>
                        <tr>
                            <td>LongBench</td>
                            <td><span class="model-label Specialization">ChatGLM2-6B</span></td>
                            <td>24.9</td>
                            <td>25.7</td>
                        </tr>
                        <tr>
                            <td>LooGLE</td>
                            <td><span class="model-label Specialization">ChatGLM2-6b-32k</span></td>
                            <td>19.6</td>
                            <td>15.1</td>
                        </tr>
                        <tr>
                            <td>RULER</td>
                            <td><span class="model-label Retrieval">Llama-3.1-8B-Instruct</span></td>
                            <td>90.7</td>
                            <td>88.3</td>
                        </tr>
                        <tr>
                            <td rowspan="3">Retrieval</td>
                            <td>InfiniteBench</td>
                            <td><span class="model-label Specialization">ChatGLM3-6b-128k</span></td>
                            <td>24.5</td>
                            <td>19.5</td>
                        </tr>
                        <tr>
                            <td>NIAH</td>
                            <td><span class="model-label Retrieval">Llama-3.1-8B-Instruct</span></td>
                            <td>97.6</td>
                            <td>-</td>
                        </tr>
                        <tr>
                            <td>NThread</td>
                            <td><span class="model-label Retrieval">Llama-3.1-8B-Instruct</span></td>
                            <td>34.3</td>
                            <td>41.4</td>
                        </tr>
                        <tr>
                            <td>Generation</td>
                            <td>LongWriter</td>
                            <td><span class="model-label Retrieval">Llama-3.1-8B-Instruct</span></td>
                            <td>58.5</td>
                            <td>60.3</td>
                        </tr>
                        <tr>
                            <td>Specialization</td>
                            <td>LIBRA</td>
                            <td><span class="model-label Retrieval">Llama-3-8B-Instruct</span></td>
                            <td>56.8</td>
                            <td>57.4</td>
                        </tr>
                        <tr>
                            <td>Faithfulness</td>
                            <td>L_CiteEval</td>
                            <td><span class="model-label Retrieval">Llama-3.1-8B-Instruct</span></td>
                            <td>27.7</td>
                            <td>25.5</td>
                        </tr>
                    </tbody>
                </table>
            </div>
        </section>
        <section class="citation">
            <h2><i class="fas fa-video"></i>  *************** </h2>
            <p>
                Á©∫
            </p>
            <video>
                Á©∫
            </video>
         </section>
                
        <section class="citation">
            <h2><i class="fas fa-quote-right"></i> BibTeX</h2>
            <div class="citation-container">
                <button class="copy-button" onclick="copyBibTeX()">
                    <i class="fas fa-copy"></i> Copy
                </button>
                <pre id="bibtex">@misc{,
    title={LOOM-Scope: LOng-cOntext Model evaluation framework }, 
    author={ },
    year={2025},
    eprint={2504.19093},
    archivePrefix={arXiv},
    primaryClass={cs.CR},
    url={}, 
}</pre>
            </div>
        </section>

        <script>
        function copyBibTeX() {
            const bibtex = document.getElementById('bibtex').textContent;
            navigator.clipboard.writeText(bibtex).then(() => {
                const button = document.querySelector('.copy-button');
                const originalContent = button.innerHTML;
                button.innerHTML = '<i class="fas fa-check"></i> Copied!';
                setTimeout(() => {
                    button.innerHTML = originalContent;
                }, 2000);
            });
        }
        </script>
    </main>
</body>
</html> 