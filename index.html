<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>LOOM-Scope - LOng-cOntext Model evaluation framework</title>
    <meta name="description" content="Providing a convient and comprehensive framework for long-context model evaluation.">
    <link rel="stylesheet" href="styles.css">
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.5.1/css/all.min.css">
    <style>

        .evaluation {
            overflow-x: auto;
            margin: 20px 0;
            padding: 0 20px;
            width: 100%;
            max-width: 100%;
            -webkit-overflow-scrolling: touch; /* ‰∏∫iOSËÆæÂ§áÊ∑ªÂä†Âπ≥ÊªëÊªöÂä® */
        }

        .evaluation .table-container {
            width: 100%;
            overflow-x: auto;
            margin-bottom: 20px;
        }

        
        .evaluation table {
            border-collapse: collapse;
            min-width: 100%;
            width: max-content;
            margin: 20px auto;
            font-size: 14px;
        }
        
        .evaluation th, .evaluation td {
            padding: 8px 15px;
            text-align: center;
            border: none;
            min-width: 80px;
            white-space: nowrap; /* Èò≤Ê≠¢ÂÜÖÂÆπÊç¢Ë°å */
        }
        
        .evaluation tbody tr {
            border-bottom: 1px solid #ddd;
        }
        
        
        .evaluation thead tr {
            border-bottom: 2px solid #000;
        }
        
        .evaluation th {
            background-color: transparent;
            font-weight: bold;
            white-space: nowrap;
            height: 40px;
            position: sticky; /* Âõ∫ÂÆöË°®Â§¥ */
            top: 0;
            background: white; /* Á°Æ‰øùË°®Â§¥‰∏çÈÄèÊòé */
            z-index: 1;
        }
        
        .evaluation th.rank-col {
            min-width: 60px;
            position: sticky; /* Âõ∫ÂÆöÁ¨¨‰∏ÄÂàó */
            left: 0;
            z-index: 2;
            background: white;
        }
        
        .evaluation th.type-col {
            min-width: 120px;
        }
        
        .evaluation th.model-col {
            min-width: 200px;
        }
        
        .evaluation th.score-col {
            min-width: 100px;
        }
        
        .evaluation th.algorithm-col {
            min-width: 100px;
        }
        .Generation{
            background-color: #e8f5e9
        }
        .General{
            background-color: #f5f5f5;
        }
        .Reasoning{
            background-color: #86ccec;
        }
        .Retrieve{
            background-color: #ffebee
        }
        .Faithfulness{
            background-color: #d4cc83
        }
        .Specialization{
            background-color: #e3f2fd;
        }

        
        .evaluation tr:hover {
            background-color: #f5f5f5;
        }
        .Llama {
            background-color: #ffebee
        }
        
        .model-type-reasoning {
            background-color: #e8f5e9;
        }
        
        .Qwen {
            background-color: #e3f2fd;
        }
        
        .algorithm-group {
            border-left: none;
            padding-left: 15px;
            font-weight: bold;
        }
        
        .model-type-legend {
            display: flex;
            justify-content: center;
            gap: 20px;
            margin: 10px 0;
        }
        
        .legend-item {
            display: flex;
            align-items: center;
            gap: 5px;
        }
        
        .legend-color {
            width: 20px;
            height: 20px;
            border-radius: 4px;
        }

        .best-score {
            font-weight: bold;
        }

        .second-best {
            text-decoration: underline;
        }

        .basic-header {
            height: 60px !important;
        }

        .evaluation::-webkit-scrollbar {
            height: 8px;
        }

        .evaluation::-webkit-scrollbar-track {
            background: #f1f1f1;
            border-radius: 4px;
        }

        .evaluation::-webkit-scrollbar-thumb {
            background: #888;
            border-radius: 4px;
        }

        .evaluation::-webkit-scrollbar-thumb:hover {
            background: #555;
        }
    </style>
</head>
<body>
    <main>
        <section class="hero">
            <div class="logo">
                <i class="fas fa-shield-alt"></i>
            </div>
            <h1>LOOM-Scope</h1>
            <h2>Providing a convient and comprehensive framework for long-context model evaluation.</h2>
            
            <div class="authors">
                <p>
                    <i class="fas fa-users"></i>
                    NONE
                </p>
                <p class="affiliations">
                    <i class="fas fa-university"></i>
                    NONE
                </p>
            </div>
            
            <div class="nav-buttons">
                <a href="" class="button">
                    <i class="fas fa-file-alt"></i>
                    PaperÔºàNONE)
                </a>
                <a href="" class="button">
                    <i class="fab fa-github"></i>
                    CodeÔºàNONE)
                </a>
                <a href="" class="button">
                    <i class="fas fa-database"></i>
                    DataÔºàNONE)
                </a>
            </div>
        </section>

        <section class="introduction">
            <h2><i class="fas fa-info-circle"></i> Introduction</h2>
            <div class="overview-image">
                <img src="images/newplot.png" alt="LOOM-Scope Overview" class="full-width-image">
                <p class="image-caption"></i> Overview of LOOM-Scope</p>
            </div>
            <p> üåê LOOM-Scope offers a comprehensive suite of tools, featuring 15 standard long-context benchmarks covering faithfulness, retrieval, reasoning, generation, and more. With hundreds of subtasks and support for diverse model architectures‚Äîincluding Transformers, Mamba, and RWKV‚Äîit enables researchers to rigorously assess model capabilities under real-world long-context demands. A standout feature is its single-line command workflow, automating dataset/model detection, download, and evaluation for seamless usability.<br>

                üöÄ Efficiency is at the core of LOOM-Scope: it integrates 12 computational acceleration methods like CakeKV and FlexPrefill, leveraging vLLM for fast, memory-efficient inference. This makes it compatible with a range of hardware, from 24GB 3090 to 96GB H20 GPUs, with publicly documented computational costs and reproducible results across platforms. Whether evaluating base models or adapters (via HuggingFace PEFT), LOOM-Scope ensures consistency and scalability.<br>
                
                üîÑ By bridging model compatibility, benchmark diversity, and inference optimization, LOOM-Scope empowers the research community to push the boundaries of long-context LLMs. Our evaluation results highlight strengths and gaps in current models, guiding future advancements in context handling, reasoning, and retrieval-augmented generation. Dive into LOOM-Scope to unlock systematic, efficient long-context model evaluation.<br>
                
        </section>

        <section class="evaluation">
            <h2><i class="fas fa-chart-bar"></i> Model leaderboard</h2>
            <div class="table-container">
                <table>
                    <thead>
                        <tr>
                            <th rowspan="3" class="basic-header rank-col">Rank</th>
                            <th rowspan="2" class="basic-header model-col">Model</th>
                            <th rowspan="2" class="basic-header score-col">Avg Score</th>
                            <th colspan="1" class="algorithm-group">Faithfulness</th>
                            <th colspan="4" class="algorithm-group">General</th>
                            <th colspan="5" class="algorithm-group">Reasoning</th>
                            <th colspan="3" class="algorithm-group">Retrieve</th>
                            <th colspan="1" class="algorithm-group">Generation</th>
                            <th colspan="1" class="algorithm-group">Specialization</th>
                        </tr>
                        <tr>
                            <th class="algorithm-col">L_CiteEval</th>
                            <th class="algorithm-col">LEval</th>
                            <th class="algorithm-col">LooGLE</th>
                            <th class="algorithm-col">RULERÔºà0-128kÔºâ</th>
                            <th class="algorithm-col">longbench</th>
                            <th class="algorithm-col">babilongÔºà0-128kÔºâ</th>
                            <th class="algorithm-col">Counting-Stars</th>
                            <th class="algorithm-col">LongIns</th>
                            <th class="algorithm-col">LVEval</th>
                            <th class="algorithm-col">longbench_v2</th>
                            <th class="algorithm-col">NIAH</th>
                            <th class="algorithm-col">NThread</th>
                            <th class="algorithm-col">InfiniteBench</th>
                            <th class="algorithm-col">LongWriter</th>
                            <th class="algorithm-col">LIBRA</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td>1</td>
                            <td><span class="model-label Qwen">Qwen3-30B-A3B</span></td>
                            <td class="best-score">46.08</td> 
                            <td>37.96</td>
                            <td>40.61</td>
                            <td>11.61</td>
                            <td>78.32</td>
                            <td>43.24</td>
                            <td>60.31</td>
                            <td>48.96</td>
                            <td>41.30</td>
                            <td>22.82</td>
                            <td>28.42</td>
                            <td>100.00</td>
                            <td>24.12</td>
                            <td>14.14</td>
                            <td>83.24</td>
                            <td>56.09</td>
                        </tr>    
                        <tr>
                            <td>2</td>
                            <td><span class="model-label Qwen">Qwen3-14B</span></td>
                            <td class="best-score">45.97</td>
                            <td>35.64</td>
                            <td>43.84</td>
                            <td>11.79</td>
                            <td>74.94</td>
                            <td>45.47</td>
                            <td>59.15</td>
                            <td>56.41</td>
                            <td>31.95</td>
                            <td>21.26</td>
                            <td>29.85</td>
                            <td>100.00</td>
                            <td>27.35</td>
                            <td>10.24</td>
                            <td>85.75</td>
                            <td>55.87</td>
                        </tr>
                        <tr>
                            <td>3</td>
                            <td><span class="model-label Llama">Meta-Llama-3.1-8B-Instruct</span></td>
                            <td class="best-score">41.37</td>
                            <td>25.79</td>
                            <td>39.70</td>
                            <td>11.81</td>
                            <td>86.79</td>
                            <td>37.94</td>
                            <td>57.42</td>
                            <td>37.68</td>
                            <td>25.40</td>
                            <td>25.66</td>
                            <td>30.40</td>
                            <td>91.00</td>
                            <td>20.06</td>
                            <td>33.64</td>
                            <td>45.96</td>
                            <td>51.24</td>
                        </tr>
                        <tr>
                            <td>4</td>
                            <td><span class="model-label Qwen">Qwen3-8B/span></td>
                            <td class="best-score">40.18</td>
                            <td>33.18</td>
                            <td>41.15</td>
                            <td>11.67</td>
                            <td>67.68</td>
                            <td>38.62</td>
                            <td>55.28</td>
                            <td>52.32</td>
                            <td>32.61</td>
                            <td>15.15</td>
                            <td>27.25</td>
                            <td>64.00</td>
                            <td>21.92</td>
                            <td>8.06</td>
                            <td>81.99</td>
                            <td>51.78</td>
                        </tr>
                        <tr>
                            <td>5</td>
                            <td><span class="model-label Qwen">Qwen3-4B/span></td>
                            <td class="best-score">38.70</td>
                            <td>24.55</td>
                            <td>39.03</td>
                            <td>11.69</td>
                            <td>70.29</td>
                            <td>39.32</td>
                            <td>55.01</td>
                            <td>42.06</td>
                            <td>33.66</td>
                            <td>18.24</td>
                            <td>32.52</td>
                            <td>62.00</td>
                            <td>17.95</td>
                            <td>13.05</td>
                            <td>74.25</td>
                            <td>46.92</td>
                        </tr>    
                    </tbody>
                </table>
            </div>
        </section>
        <section class="evaluation">
            <h2><i class="fa-solid fa-database"></i> Benchmark Validation Platform</h2>
            <div class="table-container">
                <table>
                    <thead>
                        <tr>
                            <th rowspan="3" class="basic-header rank-col">Ability</th>
                            <th rowspan="3" class="basic-header rank-col">Benchmark</th>
                            <th rowspan="3" class="basic-header rank-col">Model</th>
                            <th rowspan="3" class="basic-header model-col">Scores (Evaluated)</th>
                            <th rowspan="3" class="basic-header score-col">Official Scores (Reported in Paper)</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><span class="benchmark-label Reasoning">Reasoning/span></td>
                            <td>babilong</td>
                            <td>Llama-3.1-8B-Instruct</td>
                            <td>57.0</td>
                            <td>59.0</td>
                        </tr>
                        <tr>
                            <td><span class="benchmark-label Reasoning">Reasoning/span></td>
                            <td>Counting_Stars</td>
                            <td>Llama-3.1-8B-Instruct\GLM-4</td>
                            <td>38.2</td>
                            <td>43.5</td>
                        </tr>
                        <tr>
                            <td><span class="benchmark-label Reasoning">Reasoning/span></td>
                            <td>LongBench_v2</td>
                            <td>Llama-3.1-8B-Instruct</td>
                            <td>30.4</td>
                            <td>30.0</td>
                        </tr>
                        <tr>
                            <td><span class="benchmark-label Reasoning">Reasoning/span></td>
                            <td>LongIns</td>
                            <td>ChatGLM2-6B</td>
                            <td>11.5</td>
                            <td>12.0</td>
                        </tr>
                        <tr>
                            <td><span class="benchmark-label Reasoning">Reasoning/span></td>
                            <td>LVEval</td>
                            <td>Llama2-7B-32k-Instruct</td>
                            <td>7.3</td>
                            <td>7.4</td>
                        </tr>
                        <tr>
                            <td><span class="benchmark-label General">General/span></td>
                            <td>LEval</td>
                            <td>Llama-3.1-8B-Instruct</td>
                            <td>60.52</td>
                            <td>58.72</td>
                        </tr>
                        <tr>
                            <td><span class="benchmark-label General">General/span></td>
                            <td>LongBench</td>
                            <td>ChatGLM2-6B</td>
                            <td>24.9</td>
                            <td>25.7</td>
                        </tr>
                        <tr>
                            <td><span class="benchmark-label General">General/span></td>
                            <td>LooGLE</td>
                            <td>chatglm2-6b-32k</td>
                            <td>19.6</td>
                            <td>15.1</td>
                        </tr>
                        <tr>
                            <td><span class="benchmark-label General">General/span></td>
                            <td>RULER</td>
                            <td>Llama-3.1-8B-Instruct</td>
                            <td>90.7</td>
                            <td>88.3</td>
                        </tr>
                        <tr>
                            <td><span class="benchmark-label Retrieve">Retrieve/span></td>
                            <td>InfiniteBench</td>
                            <td>chatglm3-6b-128k</td>
                            <td>24.5</td>
                            <td><19.46</td>
                        </tr>
                        <tr>
                            <td><span class="benchmark-label Retrieve">Retrieve/span></td>
                            <td>NIAH</td>
                            <td>Llama-3.1-8B-Instruct</td>
                            <td>97.6</td>
                            <td>-</td>
                        </tr>
                        <tr>
                            <td><span class="benchmark-label Retrieve">Retrieve/span></td>
                            <td>NThread</td>
                            <td>Llama-3.1-8B-Instruct</td>
                            <td>34.3</td>
                            <td>41.4</td>
                        </tr>
                        <tr>
                            <td><span class="benchmark-label Generation">Generation/span></td>
                            <td>LongWriter</td>
                            <td>Llama-3.1-8B-Instruct</td>
                            <td>58.5</td>
                            <td>60.3</td>
                        </tr>
                        <tr>
                            <td><span class="benchmark-label Specialization">Specialization/span></td>
                            <td>LIBRA</td>
                            <td>Llama-3-8B-Instruct</td>
                            <td>56.8</td>
                            <td>57.4</td>
                        </tr>
                        <tr>
                            <td><span class="benchmark-label Faithfulness">Faithfulness/span></td>
                            <td>L_CiteEval</td>
                            <td>Llama-3.1-8B-Instruct</td>
                            <td>27.7</td>
                            <td>25.5</td>
                        </tr>
                    </tbody>
                </table>

        </section>

                
        <section class="citation">
            <h2><i class="fas fa-quote-right"></i> BibTeX</h2>
            <div class="citation-container">
                <button class="copy-button" onclick="copyBibTeX()">
                    <i class="fas fa-copy"></i> Copy
                </button>
                <pre id="bibtex">@misc{,
    title={LOOM-Scope: LOng-cOntext Model evaluation framework }, 
    author={ },
    year={2025},
    eprint={2504.19093},
    archivePrefix={arXiv},
    primaryClass={cs.CR},
    url={}, 
}</pre>
            </div>
        </section>

        <script>
        function copyBibTeX() {
            const bibtex = document.getElementById('bibtex').textContent;
            navigator.clipboard.writeText(bibtex).then(() => {
                const button = document.querySelector('.copy-button');
                const originalContent = button.innerHTML;
                button.innerHTML = '<i class="fas fa-check"></i> Copied!';
                setTimeout(() => {
                    button.innerHTML = originalContent;
                }, 2000);
            });
        }
        </script>
    </main>
</body>
</html> 